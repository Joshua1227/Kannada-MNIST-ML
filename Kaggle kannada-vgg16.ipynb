{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz\")['arr_0']\n",
    "test_images = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz\")['arr_0']\n",
    "train_labels = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz\")['arr_0']\n",
    "test_labels = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3D(c_x, padlen=1):\n",
    "    m,n,r = c_x.shape\n",
    "    c_y = np.zeros((m, n+2*padlen, r+2*padlen),dtype=c_x.dtype)\n",
    "    c_y[:, padlen:-padlen, padlen:-padlen] = c_x\n",
    "    return c_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_reshape = resize(train_images, (60000, 48, 48))\n",
    "train_images = pad3D(train_images, padlen=2)\n",
    "train_images.shape\n",
    "test_images = pad3D(test_images, padlen=2)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(train_images, axis=-1)\n",
    "x_test = np.expand_dims(test_images, axis=-1)\n",
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_test = keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.01, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights=None, include_top=True, input_shape=(32, 32, 1), pooling = 'avg', classes = 10)\n",
    "#model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/15\n",
      "59400/59400 [==============================] - 136s 2ms/step - loss: 2.2165 - acc: 0.1596 - f1_m: 0.0466 - precision_m: 0.1051 - recall_m: 0.0335 - val_loss: 1.1497 - val_acc: 0.4750 - val_f1_m: 0.4588 - val_precision_m: 0.7045 - val_recall_m: 0.3417\n",
      "Epoch 2/15\n",
      "59400/59400 [==============================] - 138s 2ms/step - loss: 0.1726 - acc: 0.9491 - f1_m: 0.9482 - precision_m: 0.9573 - recall_m: 0.9407 - val_loss: 0.0977 - val_acc: 0.9833 - val_f1_m: 0.9833 - val_precision_m: 0.9850 - val_recall_m: 0.9817\n",
      "Epoch 3/15\n",
      "59400/59400 [==============================] - 140s 2ms/step - loss: 0.0560 - acc: 0.9873 - f1_m: 0.9874 - precision_m: 0.9893 - recall_m: 0.9856 - val_loss: 0.0403 - val_acc: 0.9933 - val_f1_m: 0.9917 - val_precision_m: 0.9933 - val_recall_m: 0.9900\n",
      "Epoch 4/15\n",
      "59400/59400 [==============================] - 140s 2ms/step - loss: 0.0837 - acc: 0.9814 - f1_m: 0.9816 - precision_m: 0.9847 - recall_m: 0.9785 - val_loss: 0.0985 - val_acc: 0.9767 - val_f1_m: 0.9791 - val_precision_m: 0.9832 - val_recall_m: 0.9750\n",
      "Epoch 5/15\n",
      "59400/59400 [==============================] - 140s 2ms/step - loss: 0.0804 - acc: 0.9832 - f1_m: 0.9837 - precision_m: 0.9867 - recall_m: 0.9808 - val_loss: 0.0389 - val_acc: 0.9967 - val_f1_m: 0.9958 - val_precision_m: 0.9983 - val_recall_m: 0.9933\n",
      "Epoch 6/15\n",
      "59400/59400 [==============================] - 140s 2ms/step - loss: 0.0310 - acc: 0.9924 - f1_m: 0.9926 - precision_m: 0.9936 - recall_m: 0.9916 - val_loss: 0.0667 - val_acc: 0.9800 - val_f1_m: 0.9833 - val_precision_m: 0.9883 - val_recall_m: 0.9783\n",
      "Epoch 7/15\n",
      "59400/59400 [==============================] - 142s 2ms/step - loss: 0.0273 - acc: 0.9939 - f1_m: 0.9939 - precision_m: 0.9946 - recall_m: 0.9931 - val_loss: 0.0382 - val_acc: 0.9917 - val_f1_m: 0.9925 - val_precision_m: 0.9933 - val_recall_m: 0.9917\n",
      "Epoch 8/15\n",
      "59400/59400 [==============================] - 175s 3ms/step - loss: 0.0750 - acc: 0.9840 - f1_m: 0.9842 - precision_m: 0.9877 - recall_m: 0.9808 - val_loss: 0.0669 - val_acc: 0.9850 - val_f1_m: 0.9866 - val_precision_m: 0.9899 - val_recall_m: 0.9833\n",
      "Epoch 9/15\n",
      "59400/59400 [==============================] - 183s 3ms/step - loss: 0.0380 - acc: 0.9919 - f1_m: 0.9917 - precision_m: 0.9935 - recall_m: 0.9900 - val_loss: 0.0846 - val_acc: 0.9867 - val_f1_m: 0.9883 - val_precision_m: 0.9900 - val_recall_m: 0.9867\n",
      "Epoch 10/15\n",
      "59400/59400 [==============================] - 185s 3ms/step - loss: 0.0233 - acc: 0.9944 - f1_m: 0.9944 - precision_m: 0.9954 - recall_m: 0.9934 - val_loss: 0.0263 - val_acc: 0.9933 - val_f1_m: 0.9933 - val_precision_m: 0.9933 - val_recall_m: 0.9933\n",
      "Epoch 11/15\n",
      "50176/59400 [========================>.....] - ETA: 27s - loss: 0.1172 - acc: 0.9796 - f1_m: 0.9794 - precision_m: 0.9847 - recall_m: 0.9745"
     ]
    } 
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', \n",
    "              metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          #callbacks=[mcp_save],\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(shear_range = 0.5)\n",
    "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n",
    "test_nb_samples = len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"Kannada_MNIST_npz/Dig_MNIST/X_dig_MNIST.npz\")['arr_0']\n",
    "labels = np.load(\"Kannada_MNIST_npz/Dig_MNIST/y_dig_MNIST.npz\")['arr_0']\n",
    "images_resized = pad3D(images, padlen=2)\n",
    "x_digi_test = np.expand_dims(images_resized, axis=-1)\n",
    "y_digi_test = keras.utils.to_categorical(labels)\n",
    "datagen = ImageDataGenerator(shear_range = 0.5)\n",
    "digi_generator = datagen.flow(x_digi_test, y_digi_test, batch_size=batch_size)\n",
    "digi_nb_samples = len(y_digi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(confusion_matrix, y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix#confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes#[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, f1, precision, recall = model.evaluate_generator(test_generator,steps = len(test_generator), verbose=0)\n",
    "print(\"acc: \", acc,\"\\n f1: \",f1,\"\\nprecion: \", precision, \"\\nrecall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, f1, precision, recall = model.evaluate_generator(digi_generator,steps = len(test_generator), verbose=0)\n",
    "print(\"acc: \", acc,\"\\n f1: \",f1,\"\\nprecision: \", precision, \"\\nrecall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(x_test, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "report = classification_report(np.argmax(y_test, axis=1), predicted, digits = 4)\n",
    "confusion_matrix = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=predicted)\n",
    "print(report)\n",
    "plot_confusion_matrix(confusion_matrix,y_true=np.argmax(y_test, axis=1), y_pred=predicted, classes=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(x_digi_test, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "report = classification_report(np.argmax(y_digi_test, axis=1), predicted, digits = 4)\n",
    "confusion_matrix = confusion_matrix(y_true=np.argmax(y_digi_test, axis=1), y_pred=np.argmax(pred, axis=1))\n",
    "print(report)\n",
    "plot_confusion_matrix(confusion_matrix,y_true=np.argmax(y_digi_test, axis=1), y_pred=predicted, classes=['0','1','2','3','4','5','6','7','8','9'],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_cm(np.argmax(y_digi_test, axis=1), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(x_test, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "confusion_matrix = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
