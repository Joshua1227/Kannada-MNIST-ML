{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz\")['arr_0']\n",
    "test_images = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz\")['arr_0']\n",
    "train_labels = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz\")['arr_0']\n",
    "test_labels = np.load(\"Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3D(c_x, padlen=1):\n",
    "    m,n,r = c_x.shape\n",
    "    c_y = np.zeros((m, n+2*padlen, r+2*padlen),dtype=c_x.dtype)\n",
    "    c_y[:, padlen:-padlen, padlen:-padlen] = c_x\n",
    "    return c_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_reshape = resize(train_images, (60000, 48, 48))\n",
    "train_images = pad3D(train_images, padlen=2)\n",
    "train_images.shape\n",
    "test_images = pad3D(test_images, padlen=2)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(train_images, axis=-1)\n",
    "x_test = np.expand_dims(test_images, axis=-1)\n",
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_test = keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.01, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.applications.ResNet50(weights=None, include_top=True, input_shape=(32, 32, 1), pooling = 'avg', classes = 10)\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daniel/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Train on 59400 samples, validate on 600 samples\n",
      "Epoch 1/15\n",
      "59400/59400 [==============================] - 109s 2ms/step - loss: 0.3294 - acc: 0.9086 - f1_m: 0.9081 - precision_m: 0.9192 - recall_m: 0.8987 - val_loss: 0.0811 - val_acc: 0.9717 - val_f1_m: 0.9732 - val_precision_m: 0.9781 - val_recall_m: 0.9683\n",
      "Epoch 2/15\n",
      "59400/59400 [==============================] - 107s 2ms/step - loss: 0.0655 - acc: 0.9793 - f1_m: 0.9796 - precision_m: 0.9813 - recall_m: 0.9778 - val_loss: 0.1479 - val_acc: 0.9517 - val_f1_m: 0.9533 - val_precision_m: 0.9549 - val_recall_m: 0.9517\n",
      "Epoch 3/15\n",
      "59400/59400 [==============================] - 131s 2ms/step - loss: 0.0403 - acc: 0.9873 - f1_m: 0.9874 - precision_m: 0.9884 - recall_m: 0.9864 - val_loss: 0.0594 - val_acc: 0.9800 - val_f1_m: 0.9816 - val_precision_m: 0.9833 - val_recall_m: 0.9800\n",
      "Epoch 4/15\n",
      "59400/59400 [==============================] - 145s 2ms/step - loss: 0.0270 - acc: 0.9913 - f1_m: 0.9913 - precision_m: 0.9918 - recall_m: 0.9909 - val_loss: 0.0393 - val_acc: 0.9850 - val_f1_m: 0.9850 - val_precision_m: 0.9850 - val_recall_m: 0.9850\n",
      "Epoch 5/15\n",
      "59400/59400 [==============================] - 162s 3ms/step - loss: 0.0232 - acc: 0.9932 - f1_m: 0.9932 - precision_m: 0.9935 - recall_m: 0.9928 - val_loss: 0.0936 - val_acc: 0.9767 - val_f1_m: 0.9808 - val_precision_m: 0.9849 - val_recall_m: 0.9767\n",
      "Epoch 6/15\n",
      "59400/59400 [==============================] - 170s 3ms/step - loss: 0.0523 - acc: 0.9853 - f1_m: 0.9852 - precision_m: 0.9865 - recall_m: 0.9839 - val_loss: 0.0889 - val_acc: 0.9767 - val_f1_m: 0.9741 - val_precision_m: 0.9765 - val_recall_m: 0.9717\n",
      "Epoch 7/15\n",
      "59400/59400 [==============================] - 179s 3ms/step - loss: 0.0641 - acc: 0.9820 - f1_m: 0.9822 - precision_m: 0.9836 - recall_m: 0.9807 - val_loss: 0.0155 - val_acc: 0.9950 - val_f1_m: 0.9950 - val_precision_m: 0.9950 - val_recall_m: 0.9950\n",
      "Epoch 8/15\n",
      "59400/59400 [==============================] - 182s 3ms/step - loss: 0.0403 - acc: 0.9887 - f1_m: 0.9887 - precision_m: 0.9895 - recall_m: 0.9878 - val_loss: 0.1419 - val_acc: 0.9550 - val_f1_m: 0.9541 - val_precision_m: 0.9565 - val_recall_m: 0.9517\n",
      "Epoch 9/15\n",
      "59400/59400 [==============================] - 178s 3ms/step - loss: 0.0568 - acc: 0.9844 - f1_m: 0.9845 - precision_m: 0.9863 - recall_m: 0.9827 - val_loss: 0.6964 - val_acc: 0.8683 - val_f1_m: 0.8679 - val_precision_m: 0.8708 - val_recall_m: 0.8650\n",
      "Epoch 10/15\n",
      "59400/59400 [==============================] - 190s 3ms/step - loss: 0.0956 - acc: 0.9769 - f1_m: 0.9771 - precision_m: 0.9792 - recall_m: 0.9751 - val_loss: 0.0393 - val_acc: 0.9900 - val_f1_m: 0.9883 - val_precision_m: 0.9900 - val_recall_m: 0.9867\n",
      "Epoch 11/15\n",
      "59400/59400 [==============================] - 185s 3ms/step - loss: 0.0254 - acc: 0.9919 - f1_m: 0.9920 - precision_m: 0.9926 - recall_m: 0.9913 - val_loss: 0.6364 - val_acc: 0.9183 - val_f1_m: 0.9194 - val_precision_m: 0.9256 - val_recall_m: 0.9133\n",
      "Epoch 12/15\n",
      "59400/59400 [==============================] - 185s 3ms/step - loss: 0.0777 - acc: 0.9799 - f1_m: 0.9799 - precision_m: 0.9815 - recall_m: 0.9783 - val_loss: 0.0242 - val_acc: 0.9933 - val_f1_m: 0.9933 - val_precision_m: 0.9933 - val_recall_m: 0.9933\n",
      "Epoch 13/15\n",
      "59400/59400 [==============================] - 183s 3ms/step - loss: 0.0238 - acc: 0.9927 - f1_m: 0.9928 - precision_m: 0.9933 - recall_m: 0.9923 - val_loss: 0.0175 - val_acc: 0.9950 - val_f1_m: 0.9958 - val_precision_m: 0.9967 - val_recall_m: 0.9950\n",
      "Epoch 14/15\n",
      "59400/59400 [==============================] - 192s 3ms/step - loss: 0.0166 - acc: 0.9951 - f1_m: 0.9951 - precision_m: 0.9953 - recall_m: 0.9948 - val_loss: 0.2636 - val_acc: 0.9250 - val_f1_m: 0.9258 - val_precision_m: 0.9266 - val_recall_m: 0.9250\n",
      "Epoch 15/15\n",
      "59400/59400 [==============================] - 201s 3ms/step - loss: 0.0343 - acc: 0.9916 - f1_m: 0.9917 - precision_m: 0.9924 - recall_m: 0.9910 - val_loss: 0.1214 - val_acc: 0.9667 - val_f1_m: 0.9673 - val_precision_m: 0.9714 - val_recall_m: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe935d61b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          #callbacks=[mcp_save],\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(shear_range = 0.5)\n",
    "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n",
    "test_nb_samples = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#loss, accuracy, f1_score, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Xtest loss:', loss)\n",
    "print('Xtest accuracy:', accuracy)\n",
    "#print('Xtest f1:', f1_score)\n",
    "#print('Xtest precision:', precision)\n",
    "#print('Xtest recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"Kannada_MNIST_npz/Dig_MNIST/X_dig_MNIST.npz\")['arr_0']\n",
    "labels = np.load(\"Kannada_MNIST_npz/Dig_MNIST/y_dig_MNIST.npz\")['arr_0']\n",
    "images_resized = pad3D(images, padlen=2)\n",
    "x_digi_test = np.expand_dims(images_resized, axis=-1)\n",
    "y_digi_test = keras.utils.to_categorical(labels)\n",
    "datagen = ImageDataGenerator(shear_range = 0.5)\n",
    "digi_generator = datagen.flow(x_digi_test, y_digi_test, batch_size=batch_size)\n",
    "digi_nb_samples = len(y_digi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(confusion_matrix, y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix#confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes#[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9058 \n",
      " f1:  0.9074674620628357 \n",
      "precion:  0.9129530418395996 \n",
      "recall: 0.9021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#pred = model.predict_generator(test_generator,steps = test_nb_samples)\n",
    "#predicted = np.argmax(pred, axis=1)\n",
    "loss, acc, f1, precision, recall = model.evaluate_generator(test_generator,steps = len(test_generator), verbose=0)\n",
    "print(\"acc: \", acc,\"\\n f1: \",f1,\"\\nprecion: \", precision, \"\\nrecall:\", recall)\n",
    "#report = classification_report(test_generator.classes, predicted, digits = 4)\n",
    "#confusion_matrix = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=predicted)\n",
    "#print(report)\n",
    "#plot_confusion_matrix(confusion_matrix,y_true=np.argmax(y_test, axis=1), y_pred=predicted, classes=['0','1','2','3','4','5','6','7','8','9'],\n",
    "#                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 11s 133ms/step\n",
      "acc:  0.6512064873417721 \n",
      " f1:  0.6534374567526805 \n",
      "precision:  0.6649743816520595 \n",
      "recall: 0.6424050632911392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "loss, acc, f1, precision, recall = model.evaluate_generator(digi_generator,steps = len(test_generator), verbose=1)\n",
    "print(\"acc: \", acc,\"\\n f1: \",f1,\"\\nprecision: \", precision, \"\\nrecall:\", recall)\n",
    "#pred = model.predict_generator(digi_generator,steps = digi_nb_samples)\n",
    "#predicted = np.argmax(pred, axis=1)\n",
    "##report = classification_report(np.argmax(y_digi_test, axis=1), predicted, digits = 4)\n",
    "#confusion_matrix = confusion_matrix(y_true=np.argmax(y_digi_test, axis=1), y_pred=np.argmax(pred, axis=1))\n",
    "#print(report)\n",
    "#plot_confusion_matrix(confusion_matrix,y_true=np.argmax(y_digi_test, axis=1), y_pred=predicted, classes=['0','1','2','3','4','5','6','7','8','9'],\n",
    "#                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
